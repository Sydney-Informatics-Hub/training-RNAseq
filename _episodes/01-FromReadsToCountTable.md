---
# Please do not edit this file directly; it is auto generated.
# Instead, please edit 01-FromReadsToCountTable.md in _episodes_rmd/
title: "1. From Reads To a Count Table"
subtitle: "Assessing the quality of your sequencing data"
author: "Darya Vanichkina"
date: "21/03/2019"
output: html_document
---



## Can I use my data at all?

The first step of any NGS sequencing data analysis is to assess the quality of the generated reads, to understand whether the sequencer was working properly and we can trust the generated data. To do this, we use a tool called [fastqc](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) to calculate the summary statistics about the quality for each base position across all of the generated reads. To do this:

1. Open your terminal application
2. Type the following to log on to the University's Artemis HPC. This is a "standard" Linux filesystem, which we will navigate around in and interact with using basic Unix commands. [If you need additional support in working with such an interface, we highly recommend attending one of our Unix courses, followed by our HPC series].
```
ssh yourunikey@hpc.sydney.edu.au
```

3. Type the following to add fastqc to the list of software that is available to us on the HPC:
```
module load fastqc
```

> ## Note for the curious
> 
> If you've used a terminal before, on your local machine or on a "normal" server, you may wonder why
> we couldn't just run `fastqc` as an executable directly from the command line. The reason for this is that on large,
> multi-user systems (like Artemis, or most other University HPC clusters you'll encounter in your career), specialised
> software that is not used by everybody (so pretty much all bioinformatics tools) or software where versions are updated frequently
> (like R or python) are not "linked" to your environment, and have to be explicitly added to your $PATH via the `module load` command. 
> This means that if you have developed a tool that works only with R version 3.1.2, for example, you can `module load R/3.1.2`
> and be confident that your tool will work, while your colleague can use version 3.5, which is required for a package he needs to
> run. 
> Other useful commands that can help you interact with modules are `module avail`, which tells you which modules are installed on
> the system, `module list`, which lists which modules are already active in your environment, and `module purge`, which unloads
> all of the modules you currently have loaded. This can sometimes be useful if you're having weird issues with your environment.
> 
{: .callout}


4. Download the data to the HPC. In this exercise, we will store the data in the /projects/training/ folder. You will have a /projects/RDS-YOURPROJECTID/ folder for your actual "production" projects, after you have submitted a [Research Data Management Plan](https://dashr.sydney.edu.au/) to access Artemis or RDS for HPC/storage of your research data.

```
cd /project/Training/
mkdir yourunikey
cd yourunikey
mkdir data
wget FIXME
tar -xvzf FIXME
cd ../
```

5. In order to run fastqc we will need to use a PBS script to specify the resources we'd like to use, and a script with the actual code we'd like to run. PBS stands for "portable batch system", which is the name of the system ([PBS Pro](https://en.wikipedia.org/wiki/Portable_Batch_System)) that manages the queue of jobs on Artemis. Other queuing systems include [SLURM](https://en.wikipedia.org/wiki/Slurm_Workload_Manager) and [Torque](https://en.wikipedia.org/wiki/TORQUE), which use slightly different command to achieve the same thing /so if you've used one, you can figure out how to use the others/. 

Below is an example of a basic PBS script, that will run fastqc on our dataset:

```
# fastq script

```


To submit it we would do the following:

```
qsub -P -N fastqc -l select=1:ncpus=1:mem=10gb -l walltime=10:0:0 

```




6. We 




